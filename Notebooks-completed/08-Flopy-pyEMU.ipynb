{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the PEST(++) interface around the enhanced Freyberg model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will construct a complex model independent (non-intrusive) interface around an existing `MODFLOW-NWT` model using the `python/flopy/pyemu` stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import flopy\n",
    "import pyemu\n",
    "import matplotlib as mpl\n",
    "plt.rcParams['font.size']=12\n",
    "d_d = os.path.join(\"data\",\"ex08\")\n",
    "if os.path.exists(d_d):\n",
    "    shutil.rmtree(d_d)\n",
    "os.makedirs(d_d)\n",
    "os.chdir(d_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shua784/Dropbox/github/MM2019_FloPy/Notebooks-completed/data/ex08/data/ex08/data/ex08/data/ex08\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a base directory `b_d` from which we will read in a model already created `freyberg.nam`. This will form the basis of the remainder of the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_d = os.path.join(\"..\",\"..\",\"..\",\"data\",\"freyberg_nwt\")\n",
    "b_d = '/Users/shua784/Dropbox/github/MM2019_FloPy/data/freyberg_nwt'\n",
    "nam_file = \"freyberg.nam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the existing Freyberg model. This version should run but is not yet connected with `PEST++`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that to load a model in a different folder, you supply the namefile without path and supply the path\n",
    "# to it in the model_ws variable\n",
    "m = flopy.modflow.Modflow.load(nam_file,model_ws=b_d,check=False,forgive=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can do a couple `flopy` things to move where the new model will be written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "changing model workspace...\n",
      "   .\n"
     ]
    }
   ],
   "source": [
    "ws = \".\"\n",
    "m.change_model_ws(ws,reset_external=True)\n",
    "\n",
    "# this writes all the MODFLOW files in the new location \n",
    "m.write_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we can run the model once using a `pyemu` helper\n",
    "This helper is particularly useful if you run on more than one platform (e.g. Mac and Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe_name = os.path.join(\"..\",\"..\",\"..\",\"bin\",\"mfnwt\")\n",
    "pyemu.os_utils.run(\"{0} {1}\".format(exe_name,m.name+\".nam\"),cwd=m.model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in the heads and plot them up along with the budget components\n",
    "Note that there is a historic period and a scenario with future conditions that differ. \n",
    "\n",
    "_For the future scenario, a serious drought, recharge is lower and pumping/abstraction is increased to make up for the presumed deficite in water for agriculture._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "changing model workspace...\n",
      "   /Users/shua784/Dropbox/github/MM2019_FloPy/Notebooks-completed/data/freyberg/\n"
     ]
    }
   ],
   "source": [
    "# m.model_ws = '/Users/shua784/Dropbox/github/MM2019_FloPy/Notebooks-completed/data/freyberg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/shua784/Dropbox/github/MM2019_FloPy/Notebooks-completed/data/freyberg/freyberg.hds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9d319db88fc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHeadFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_ws\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".hds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmflay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMfListBudget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_ws\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flopy/utils/binaryfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, text, precision, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_headfile_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'unknown'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 s = 'Error. Precision could not be determined for {}'.format(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flopy/utils/binaryfile.py\u001b[0m in \u001b[0;36mget_headfile_precision\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Open file, and check filesize to ensure this is not an empty file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mtotalbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/shua784/Dropbox/github/MM2019_FloPy/Notebooks-completed/data/freyberg/freyberg.hds'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110767358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "hds = flopy.utils.HeadFile(os.path.join(m.model_ws,m.name+\".hds\"),model=m)\n",
    "hds.plot(mflay=0)\n",
    "lst = flopy.utils.MfListBudget(os.path.join(m.model_ws,m.name+\".list\"))\n",
    "df = lst.get_dataframes(diff=True)[0]\n",
    "plt.figure()\n",
    "ax = df.plot(kind=\"bar\",figsize=(6,6), grid=True)\n",
    "ax.set_xticklabels([\"historic\",\"scenario\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the effect of the \"scenario\" in the second stress period with less recharge and more abstraction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot depth to water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw = m.dis.top.array - hds.get_data()[0,:,:]\n",
    "dtw = np.ma.masked_where(m.bas6.ibound[0].array==0,dtw)\n",
    "c = plt.imshow(dtw)\n",
    "plt.title('Depth to Water')\n",
    "plt.colorbar(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we can see the river and well locations expressed in the depth to water pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we are going to do is implement the scenario with parameters so we can more easy account for the stochastic nature of the forcing conditions during the scenario stress period and also make implemention of future scenarios work in this stochastic framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset scenario period recharge\n",
    "m.rch.rech[1] = m.rch.rech[0]\n",
    "# reset scenario period abstraction\n",
    "m.wel.stress_period_data[1] = m.wel.stress_period_data[0]\n",
    "m.write_input()\n",
    "pyemu.os_utils.run(\"{0} {1}\".format(exe_name,m.name+\".nam\"),cwd=m.model_ws)\n",
    "hds = flopy.utils.HeadFile(os.path.join(m.model_ws,m.name+\".hds\"),model=m)\n",
    "axes = hds.plot(mflay=0)\n",
    "\n",
    "lst = flopy.utils.MfListBudget(os.path.join(m.model_ws,m.name+\".list\"))\n",
    "df = lst.get_dataframes(diff=True)[0]\n",
    "ax = df.plot(kind=\"bar\",figsize=(6,6))\n",
    "ax.set_xticklabels([\"historic\",\"scenario\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the scenario and historic periods have the same water balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data structures related to what we want to parameterize and what we want to observe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first the parameterization of model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = []\n",
    "# here we specify which packages we wish to parameterize, \n",
    "# starting with those that do not change over time\n",
    "paks = [\"upw.hk\",\"upw.vka\",\"upw.ss\",\"upw.sy\",\"bas6.strt\",\"extra.prsity\"]\n",
    "for k in range(m.nlay):\n",
    "    props.extend([[p,k] for p in paks])\n",
    "# next we specify that we want to make parameters for recharge\n",
    "# for both stress periods (zero-based! Python style)\n",
    "props.append([\"rch.rech\",0])\n",
    "props.append([\"rch.rech\",1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we want to handle list-type parameters in two ways\n",
    "for `spatial_list_props` this will apply a multiplier distributed spatially that applied in all stress periods throughout the model\n",
    "\n",
    "for `temporal_list_props` this will apply a multiplier for each stress period applied to all the spatial locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_list_props = [[\"wel.flux\",2],[\"drn.cond\",0]]\n",
    "temporal_list_props = [[\"wel.flux\",0],[\"wel.flux\",1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next we want to set up extracting observations. First, we will setup a post-processor that will read the heads for all active cells in both stress periods - why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hds_kperk = [[0,k] for k in range(m.nlay)]\n",
    "hds_kperk.extend([[1,k] for k in range(m.nlay)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then we setup monitoring of the SFR ASCII outputs.  \n",
    "we will accumulate the first 20 reaches and last 20 reaches together to form forecasts of sw-gw exchange in the headwaters (`hw`) and tailwaters (`tw`).  Then we will also add each reach individually for monitoring as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_obs_dict = {\"hw\":np.arange(1,int(m.nrow/2))}\n",
    "sfr_obs_dict[\"tw\"] = np.arange(int(m.nrow/2),m.nrow)\n",
    "for i in range(m.nrow):\n",
    "    sfr_obs_dict[i] = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we go...\n",
    "\n",
    "This `pyemu` class has grown into a monster...it does (among other things):\n",
    "- sets up combinations of multiplier parameters for array inputs, including uniform, zones, pilot points, grids, and KL expansion types\n",
    "- sets up combinations of multiplier parameters for list inputs\n",
    "- handles several of the shitty modflow exceptions to the array and list style inputs\n",
    "- sets up large numbers of observations based on arrays or time series\n",
    "- writes .tpl, .ins, .pst, etc\n",
    "- writes a python forward run script (WAT?!)\n",
    "- writes a prior parameter covaraince matrix using geostatistical correlations\n",
    "- draws from the prior parameter covariance matrix to generate a prior parameter ensemble\n",
    "\n",
    "This will be slow because the pure python kriging...but, hey, its free!\n",
    "\n",
    "For our purposes, we will setup combinations of constant (by layer), pilot points and grid-scale parameters for each of the array-based properties we defined earlier.  This lets us explore options for parameterization and also start to understand how information flows in the history matching problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pst_helper` instance contains the `pyemu.Pst` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_helper = pyemu.helpers.PstFromFlopyModel(nam_file,new_model_ws=\"template\",org_model_ws=ws,\n",
    "                                            const_props=props,spatial_list_props=spatial_list_props,\n",
    "                                             temporal_list_props=temporal_list_props,remove_existing=True,\n",
    "                                            grid_props=props,pp_props=props,sfr_pars=True,hds_kperk=hds_kperk,\n",
    "                                             sfr_obs=sfr_obs_dict,build_prior=False,model_exe_name=\"mfnwt\",\n",
    "                                            pp_space=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, pull out the `pyemu.Pst` instance which \n",
    "#contains all the input that ultimately goes in the PEST control %%file\n",
    "pst = pst_helper.pst\n",
    "pst.npar,pst.nobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh snap!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final bits and bobs\n",
    "We need to set some realistic parameter bounds and account for expected (but stochastic) scenario conditions:\n",
    "\n",
    "`pyemu` uses `pandas` data frame format for the parameter and observation data sections. This exposes plenty of querying and bulk editing options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data\n",
    "# properties\n",
    "tag_dict = {\"hk\":[0.1,10.0],\"vka\":[0.1,10],\"strt\":[0.95,1.05]}\n",
    "for t,[l,u] in tag_dict.items():\n",
    "    t_pars = par.loc[par.parnme.apply(lambda x: t in x ),\"parnme\"]\n",
    "    par.loc[t_pars,\"parubnd\"] = u\n",
    "    par.loc[t_pars,\"parlbnd\"] = l\n",
    "\n",
    "# recharge - just change the constant recharge mult\n",
    "# for the historic and scenario stress periods\n",
    "scen_rch = [\"cn_rech5\"]\n",
    "hist_rch = [\"cn_rech4\"]\n",
    "par.loc[par.pargp.apply(lambda x: x in scen_rch),\"parubnd\"] = 0.8\n",
    "par.loc[par.pargp.apply(lambda x: x in scen_rch),\"parlbnd\"] = 0.1\n",
    "par.loc[par.pargp.apply(lambda x: x in scen_rch),\"parval1\"] = 0.4\n",
    "par.loc[par.pargp.apply(lambda x: x in hist_rch),\"parubnd\"] = 1.2\n",
    "par.loc[par.pargp.apply(lambda x: x in hist_rch),\"parlbnd\"] = 0.8\n",
    "par.loc[par.pargp.apply(lambda x: x in hist_rch),\"parval1\"] = 1.0\n",
    "\n",
    "# well abstraction - same idea here: change the historic and scenario pars\n",
    "par.loc[\"welflux_001\",\"parval1\"] = 1.5\n",
    "par.loc[\"welflux_001\",\"parlbnd\"] = 1.0\n",
    "par.loc[\"welflux_001\",\"parubnd\"] = 2.0\n",
    "par.loc[\"welflux_000\",\"parval1\"] = 1.0\n",
    "par.loc[\"welflux_000\",\"parlbnd\"] = 0.5\n",
    "par.loc[\"welflux_000\",\"parubnd\"] = 1.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given the combinations of multipliers, we need to set a hard upper bound on porosity and sy since those have physical upper limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_csv = os.path.join(pst_helper.new_model_ws,\"arr_pars.csv\")\n",
    "df = pd.read_csv(arr_csv,index_col=0)\n",
    "sy = df.model_file.apply(lambda x: \"sy\" in x)\n",
    "df.loc[:,\"upper_bound\"] = np.NaN\n",
    "df.loc[sy,\"upper_bound\"] = 0.4\n",
    "df.to_csv(arr_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table can also be written to a .tex file\n",
    "pst.write_par_summary_table(filename=\"none\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write_obs_summary_table(filename=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to copy the binaries in to `template`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_d = os.path.join(\"..\",\"..\",\"..\",\"bin\")\n",
    "enames = [f for f in os.listdir(bin_d) if not f.endswith(\".py\") and not f.endswith(\".bat\")]\n",
    "print(enames)\n",
    "for ename in enames:\n",
    "    shutil.copy2(os.path.join(bin_d,ename),os.path.join(pst_helper.new_model_ws,ename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run the process once (`noptmax=0`) to make sure its all plumbed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pestpp = \"pestpp-ies\"\n",
    "pst.control_data.noptmax = 0\n",
    "pst.write(os.path.join(pst_helper.new_model_ws,\"freyberg.pst\"))\n",
    "pyemu.os_utils.run(pestpp + \" freyberg.pst\",cwd=pst_helper.new_model_ws)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to generate the prior parameter covariance matrix and stochastic realizations.  We will use the geostatistical covariance information in the `pst_helper` instance for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pst_helper.pst.npar < 15000:\n",
    "    cov = pst_helper.build_prior(fmt=\"coo\",filename=os.path.join(pst_helper.new_model_ws,\"prior_cov.jcb\"))\n",
    "    cov = np.ma.masked_where(cov.x==0,cov.x)\n",
    "    try:\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        ax = plt.subplot(111)\n",
    "        ax.imshow(cov)\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we can make a draw from the prior parameter covariance matrix to form a prior parameter ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pst_helper.draw(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that parameters are treated in parameter group (`pargp`) blocks for this ensemble generation.  Let's plot one parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst_helper.pst.parameter_data\n",
    "pyemu.plot_utils.ensemble_helper(pe,plot_cols=par.groupby(\"pargp\").groups,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to enforce parameter bounds and save this ensemble for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe.enforce()\n",
    "pe.to_binary(os.path.join(pst_helper.new_model_ws,\"prior.jcb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just a lil 'ole Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = -1\n",
    "pst.pestpp_options[\"ies_par_en\"] = \"prior.jcb\"\n",
    "pst.write(os.path.join(pst_helper.new_model_ws,\"freyberg.pst\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to run this monte carlo locally in parallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d = \"master_mc\"\n",
    "pyemu.os_utils.start_slaves(pst_helper.new_model_ws,pestpp,\"freyberg.pst\",num_slaves=10,\n",
    "                            master_dir=m_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model output ensemble (dimensions = num_reals X num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = pd.read_csv(os.path.join(m_d,\"freyberg.0.obs.csv\"),index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot histograms on the headwater and tailwater sw-gw exchange under both historic and scenario conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "swgw = obs.loc[obs.obsnme.apply(lambda x: \"fa\" in x and  (\"tw\" in x or \"hw\" in x)),\"obsnme\"]\n",
    "swgw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sg in swgw:\n",
    "    ax = oe.loc[:,sg].hist()\n",
    "    ax.set_title(sg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets make maps of water level standard deviation - just because we can.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hds_obs = obs.loc[obs.obsnme.apply(lambda x: \"hds\" in x),:].copy()\n",
    "hds_obs.loc[:,\"k\"] = hds_obs.obsnme.apply(lambda x: int(x.split('_')[1]))\n",
    "hds_obs.loc[:,\"i\"] = hds_obs.obsnme.apply(lambda x: int(x.split('_')[2]))\n",
    "hds_obs.loc[:,\"j\"] = hds_obs.obsnme.apply(lambda x: int(x.split('_')[3]))\n",
    "hds_obs.loc[:,\"kper\"] = hds_obs.obsnme.apply(lambda x: int(x.split('_')[4]))\n",
    "hds_obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "std_hds = oe.loc[:,hds_obs.obsnme].std()\n",
    "vmin, vmax = std_hds.min(),std_hds.max()\n",
    "for kper in range(m.nper):\n",
    "    hds_kper = hds_obs.loc[hds_obs.kper==kper,:].copy()\n",
    "    std_kper = std_hds.loc[hds_kper.obsnme]\n",
    "    fig,axes = plt.subplots(1,3,figsize=(12,4))\n",
    "    for k,ax in enumerate(axes):\n",
    "        hds_k = hds_kper.loc[hds_kper.k==k,:]\n",
    "        arr = np.zeros((m.nrow,m.ncol))\n",
    "        std_k = std_kper.loc[hds_k.obsnme]\n",
    "        ax.set_aspect(\"equal\")\n",
    "        arr[hds_k.i,hds_k.j] = std_k\n",
    "        cb = ax.imshow(arr,vmin=vmin,vmax=vmax)\n",
    "        ax.set_title(\"kper:{0},k:{1}\".format(kper,k))\n",
    "cb = plt.colorbar(cb)\n",
    "cb.set_label(\"standard deviation $m$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
